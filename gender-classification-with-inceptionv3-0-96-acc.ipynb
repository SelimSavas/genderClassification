{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Library Import","metadata":{}},{"cell_type":"code","source":"# Basic Libraries\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-23T10:28:39.691706Z","iopub.execute_input":"2022-03-23T10:28:39.692074Z","iopub.status.idle":"2022-03-23T10:28:40.940548Z","shell.execute_reply.started":"2022-03-23T10:28:39.691967Z","shell.execute_reply":"2022-03-23T10:28:40.939667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TensorFlow Libraries\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras.utils import np_utils","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:15.632076Z","iopub.execute_input":"2022-03-23T11:37:15.63299Z","iopub.status.idle":"2022-03-23T11:37:15.640055Z","shell.execute_reply.started":"2022-03-23T11:37:15.632946Z","shell.execute_reply":"2022-03-23T11:37:15.638954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Other Libraries\n\nfrom sklearn.metrics import f1_score\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nplt.style.use('ggplot')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:16.145443Z","iopub.execute_input":"2022-03-23T11:37:16.145796Z","iopub.status.idle":"2022-03-23T11:37:16.160727Z","shell.execute_reply.started":"2022-03-23T11:37:16.145763Z","shell.execute_reply":"2022-03-23T11:37:16.159925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Preprocessing","metadata":{}},{"cell_type":"code","source":"MAIN_PATH = '../input/celeba-dataset/'\nDATA_PATH = MAIN_PATH + 'img_align_celeba/img_align_celeba/'\nATTRIBUTE_PATH = MAIN_PATH + 'list_attr_celeba.csv'\nPARTITION_PATH = MAIN_PATH + 'list_eval_partition.csv'\n\nEXAMPLE_PIC = DATA_PATH + '000001.jpg'\nIMG_WIDTH = 178\nIMG_HEIGHT = 218\n\nTRAINING_SAMPLES = 10000\nVALIDATION_SAMPLES = 1000\nTEST_SAMPLES = 1000\n\nBATCH_SIZE = 16\nNUM_EPOCHS = 30\nINPUT_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:19.868505Z","iopub.execute_input":"2022-03-23T11:37:19.868999Z","iopub.status.idle":"2022-03-23T11:37:19.876245Z","shell.execute_reply.started":"2022-03-23T11:37:19.868953Z","shell.execute_reply":"2022-03-23T11:37:19.873672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list_attr_celeba.csv\nattr_df = pd.read_csv(ATTRIBUTE_PATH, index_col='image_id')\nattr_df.replace(to_replace=-1, value=0, inplace=True)\n\n# Gender distribution\nplt.title('Gender Distribution')\nsns.countplot(y = 'Male', data=attr_df)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:21.177625Z","iopub.execute_input":"2022-03-23T11:37:21.178237Z","iopub.status.idle":"2022-03-23T11:37:22.255196Z","shell.execute_reply.started":"2022-03-23T11:37:21.178196Z","shell.execute_reply":"2022-03-23T11:37:22.254398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting an example\nimg = load_img(EXAMPLE_PIC)\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:26.359545Z","iopub.execute_input":"2022-03-23T11:37:26.36021Z","iopub.status.idle":"2022-03-23T11:37:26.566531Z","shell.execute_reply.started":"2022-03-23T11:37:26.360166Z","shell.execute_reply":"2022-03-23T11:37:26.565513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list_eval_partition.csv\nparti_df = pd.read_csv(PARTITION_PATH, index_col='image_id')\nparti_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:28.352245Z","iopub.execute_input":"2022-03-23T11:37:28.352519Z","iopub.status.idle":"2022-03-23T11:37:28.515884Z","shell.execute_reply.started":"2022-03-23T11:37:28.352489Z","shell.execute_reply":"2022-03-23T11:37:28.515149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Partitions\nparti_df.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:30.450176Z","iopub.execute_input":"2022-03-23T11:37:30.450678Z","iopub.status.idle":"2022-03-23T11:37:30.467004Z","shell.execute_reply.started":"2022-03-23T11:37:30.450636Z","shell.execute_reply":"2022-03-23T11:37:30.466292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Joining csv\nsampling_df = attr_df[['Male']].join(parti_df)\nsampling_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:31.870998Z","iopub.execute_input":"2022-03-23T11:37:31.873955Z","iopub.status.idle":"2022-03-23T11:37:31.969387Z","shell.execute_reply.started":"2022-03-23T11:37:31.873898Z","shell.execute_reply":"2022-03-23T11:37:31.968534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Functions for Data","metadata":{}},{"cell_type":"code","source":"def load_reshape_img(filename):\n    img = load_img(filename)\n    img_array = img_to_array(img)/255\n    img_array = img_array.reshape((1,) + img_array.shape)\n    return img_array","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:34.538068Z","iopub.execute_input":"2022-03-23T11:37:34.538349Z","iopub.status.idle":"2022-03-23T11:37:34.543135Z","shell.execute_reply.started":"2022-03-23T11:37:34.538318Z","shell.execute_reply":"2022-03-23T11:37:34.542228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sampling(partition, sample_size, sampling_df):\n    parti_mask = sampling_df['partition'] == partition\n    male_mask = sampling_df['Male'] == 1\n    female_mask = sampling_df['Male'] == 0\n    sampled_df = pd.concat([\n        sampling_df[parti_mask & male_mask].sample(sample_size//2),\n        sampling_df[parti_mask & female_mask].sample(sample_size//2)\n    ])\n    \n    if partition != 2:\n        x = np.array([load_reshape_img(DATA_PATH + filename) for filename in sampled_df.index])\n        x = x.reshape(x.shape[0], 218, 178, 3)\n        y = np_utils.to_categorical(sampled_df['Male'],2)\n    else:\n        x = []\n        y = []\n        for index, target in sampled_df.iterrows():\n            im = cv2.imread(DATA_PATH + index) # return BGR\n            im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0 # convert it to RGB for consistency\n            im = np.expand_dims(im, axis =0)\n            x.append(im)\n            y.append(target['Male'])\n            \n    return x, y","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:35.51536Z","iopub.execute_input":"2022-03-23T11:37:35.516801Z","iopub.status.idle":"2022-03-23T11:37:35.526396Z","shell.execute_reply.started":"2022-03-23T11:37:35.516748Z","shell.execute_reply":"2022-03-23T11:37:35.525657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gender_target = {0: 'Female'\n                , 1: 'Male'}\n\ndef img_to_display(filename):\n    \n    i = Image.open(filename)\n    i.thumbnail((200, 200), Image.LANCZOS)\n    \n    with BytesIO() as buffer:\n        i.save(buffer, 'jpeg')\n        return base64.b64encode(buffer.getvalue()).decode()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:36.200448Z","iopub.execute_input":"2022-03-23T11:37:36.201222Z","iopub.status.idle":"2022-03-23T11:37:36.209458Z","shell.execute_reply.started":"2022-03-23T11:37:36.20118Z","shell.execute_reply":"2022-03-23T11:37:36.208662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_result(filename, prediction, target):\n    \n    gender = 'Male'\n    gender_icon = \"https://i.imgur.com/nxWan2u.png\"\n        \n    if prediction[1] <= 0.5:\n        gender_icon = \"https://i.imgur.com/oAAb8rd.png\"\n        gender = 'Female'\n            \n    display_html = '''\n    <div style=\"overflow: auto;  border: 2px solid #D8D8D8;\n        padding: 5px; width: 420px;\" >\n        <img src=\"data:image/jpeg;base64,{}\" style=\"float: left;\" width=\"200\" height=\"200\">\n        <div style=\"padding: 10px 0px 0px 20px; overflow: auto;\">\n            <img src=\"{}\" style=\"float: left;\" width=\"40\" height=\"40\">\n            <h3 style=\"margin-left: 50px; margin-top: 2px;\">{}</h3>\n            <p style=\"margin-left: 50px; margin-top: -6px; font-size: 12px\">{} prob.</p>\n            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Real Target: {}</p>\n            <p style=\"margin-left: 50px; margin-top: -16px; font-size: 12px\">Filename: {}</p>\n        </div>\n    </div>\n    '''.format(img_to_display(filename)\n               , gender_icon\n               , gender\n               , \"{0:.2f}%\".format(round(max(prediction)*100,2))\n               , gender_target[target]\n               , filename.split('/')[-1]\n               )\n\n    display(HTML(display_html))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:37.009172Z","iopub.execute_input":"2022-03-23T11:37:37.010013Z","iopub.status.idle":"2022-03-23T11:37:37.01715Z","shell.execute_reply.started":"2022-03-23T11:37:37.009961Z","shell.execute_reply":"2022-03-23T11:37:37.016385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gender_prediction(filename):\n    \n    im = cv2.imread(filename)\n    im = cv2.resize(cv2.cvtColor(im, cv2.COLOR_BGR2RGB), (178, 218)).astype(np.float32) / 255.0\n    im = np.expand_dims(im, axis =0)\n    \n    # prediction\n    result = model.predict(im)\n    prediction = np.argmax(result)\n    \n    return result","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:37:38.748624Z","iopub.execute_input":"2022-03-23T11:37:38.749161Z","iopub.status.idle":"2022-03-23T11:37:38.755941Z","shell.execute_reply.started":"2022-03-23T11:37:38.749116Z","shell.execute_reply":"2022-03-23T11:37:38.754916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting\nx_train, y_train = sampling(0, TRAINING_SAMPLES, sampling_df)\nx_valid, y_valid = sampling(1, VALIDATION_SAMPLES, sampling_df)\nx_test, y_test = sampling(2, TEST_SAMPLES, sampling_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Preparing the Data for the Model","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntrain_datagen.fit(x_train)\n\ntrain_generator = train_datagen.flow(x_train, y_train,batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T10:30:38.266469Z","iopub.execute_input":"2022-03-23T10:30:38.266776Z","iopub.status.idle":"2022-03-23T10:30:40.55563Z","shell.execute_reply.started":"2022-03-23T10:30:38.266744Z","shell.execute_reply":"2022-03-23T10:30:40.554679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InceptionV3_model = InceptionV3(weights='imagenet',\n                        include_top=False,\n                        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\nprint(\"number of layers:\", len(InceptionV3_model.layers))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:27.283593Z","iopub.execute_input":"2022-03-23T11:40:27.284419Z","iopub.status.idle":"2022-03-23T11:40:29.180503Z","shell.execute_reply.started":"2022-03-23T11:40:27.284363Z","shell.execute_reply":"2022-03-23T11:40:29.179648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = InceptionV3_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(512, activation=\"relu\")(x)\n\npredictions = Dense(2, activation=\"softmax\")(x)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:29.182272Z","iopub.execute_input":"2022-03-23T11:40:29.182543Z","iopub.status.idle":"2022-03-23T11:40:29.214792Z","shell.execute_reply.started":"2022-03-23T11:40:29.182507Z","shell.execute_reply":"2022-03-23T11:40:29.214103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the final model \nmodel = Model(inputs=InceptionV3_model.input, outputs=predictions)\n\n# Lock initial layers to do not be trained\nfor layer in model.layers[:52]:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:30.542491Z","iopub.execute_input":"2022-03-23T11:40:30.543285Z","iopub.status.idle":"2022-03-23T11:40:30.571935Z","shell.execute_reply.started":"2022-03-23T11:40:30.543233Z","shell.execute_reply":"2022-03-23T11:40:30.571077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=SGD(learning_rate=0.0001, momentum=0.9), \n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:33.276964Z","iopub.execute_input":"2022-03-23T11:40:33.277487Z","iopub.status.idle":"2022-03-23T11:40:33.294888Z","shell.execute_reply.started":"2022-03-23T11:40:33.277446Z","shell.execute_reply":"2022-03-23T11:40:33.294154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:35.458145Z","iopub.execute_input":"2022-03-23T11:40:35.458763Z","iopub.status.idle":"2022-03-23T11:40:35.463289Z","shell.execute_reply.started":"2022-03-23T11:40:35.458719Z","shell.execute_reply":"2022-03-23T11:40:35.462185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpointer = ModelCheckpoint(filepath='model.h5', \n                               verbose=1, \n                               save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:38.034415Z","iopub.execute_input":"2022-03-23T11:40:38.034925Z","iopub.status.idle":"2022-03-23T11:40:38.038783Z","shell.execute_reply.started":"2022-03-23T11:40:38.034882Z","shell.execute_reply":"2022-03-23T11:40:38.03804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit(train_generator, \n                 validation_data = (x_valid, y_valid), \n                 steps_per_epoch= TRAINING_SAMPLES/BATCH_SIZE, \n                 epochs= NUM_EPOCHS, \n                 callbacks=[checkpointer,callback], \n                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T11:40:43.186658Z","iopub.execute_input":"2022-03-23T11:40:43.187193Z","iopub.status.idle":"2022-03-23T12:28:16.827326Z","shell.execute_reply.started":"2022-03-23T11:40:43.187153Z","shell.execute_reply":"2022-03-23T12:28:16.826306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Success Visualization","metadata":{}},{"cell_type":"code","source":"acc = hist.history['accuracy']\nval_acc = hist.history['val_accuracy']\n\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T12:28:16.830019Z","iopub.execute_input":"2022-03-23T12:28:16.830292Z","iopub.status.idle":"2022-03-23T12:29:03.779249Z","shell.execute_reply.started":"2022-03-23T12:28:16.83026Z","shell.execute_reply":"2022-03-23T12:29:03.77842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Evaluation\nmodel.load_weights('model.h5')\npredictions = [np.argmax(model.predict(image)) for image in x_test]\naccuracy = 100 * np.sum(np.array(predictions)==y_test) / len(predictions)\nf1 = f1_score(y_test, predictions)\n\nprint('Accuracy: {:.4f}'.format(accuracy))\nprint('F1 score: {:.4f}'.format(f1))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T12:29:03.781048Z","iopub.execute_input":"2022-03-23T12:29:03.781546Z","iopub.status.idle":"2022-03-23T12:29:55.178063Z","shell.execute_reply.started":"2022-03-23T12:29:03.781506Z","shell.execute_reply":"2022-03-23T12:29:55.177293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}